{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marchitectures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from architectures import *\n",
    "from time import time\n",
    "from  matplotlib import pyplot as plt\n",
    "import timm\n",
    "import monai\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging/model')\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging/model/imaging_attention/')\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging/model/backbone/')\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging')\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging/setup')\n",
    "sys.path.append('/home/hoopersm/long_context_paper/FMImaging/setup/setup_base')\n",
    "\n",
    "from backbone import *\n",
    "from model import *\n",
    "from model.backbone import *\n",
    "from setup.setup_base import parse_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def time_run(input_shape, model, reps, padding=20):\n",
    "    model.train()\n",
    "    time_list = []\n",
    "    for rep in tqdm(range(reps+padding)):\n",
    "        start = time.time()\n",
    "        out = model(input)\n",
    "        end = time.time()\n",
    "        time_list.append(end-start)\n",
    "    print(f\"\\tAverage run time: {np.mean(time_list[padding:])} seconds\")\n",
    "    return time_list[padding:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load timing dict to track results over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists('/home/hoopersm/hyena/vit_speedup_dict.pkl'):\n",
    "    with open('/home/hoopersm/hyena/vit_speedup_dict.pkl', 'rb') as f:\n",
    "        speedup_dict = pickle.load(f)\n",
    "    key_count = len(speedup_dict)\n",
    "    print('Loaded speedup_dict with {} entries'.format(key_count))\n",
    "else:\n",
    "    speedup_dict = {}\n",
    "    key_count = 0\n",
    "    print('Initialized speedup_dict, no entries yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "in_ch = 3\n",
    "out_ch = 1\n",
    "h = 1024\n",
    "w = 1024\n",
    "t = 1\n",
    "reps = 100\n",
    "\n",
    "vit_patch = (1,16,16) # (t,h,w)\n",
    "\n",
    "input = torch.zeros(((batch,in_ch,t,h,w))).to(device='cuda') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute context length for ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ViT context length\n",
    "context_length = np.ceil(t/vit_patch[0]) * np.ceil(h/vit_patch[1]) * np.ceil(w/vit_patch[2])\n",
    "print('ViT context length: {}'.format(context_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Creating attention-based ViT model...')\n",
    "vit_attention_model = ViT(\n",
    "                            use_hyena=False,\n",
    "                            in_channels=in_ch,\n",
    "                            num_classes=out_ch,\n",
    "                            img_size=(t,h,w),\n",
    "                            spatial_dims=3,\n",
    "                            patch_size=vit_patch,\n",
    "                            classification=True\n",
    "                        ).to(device='cuda')\n",
    "attn_num_params = count_parameters(vit_attention_model)\n",
    "print(f\"\\tNumber of parameters with attention: {attn_num_params/1e6} million\")\n",
    "\n",
    "print('Running attention-based ViT timing test...')\n",
    "attn_time = time_run(input, vit_attention_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "vit_attention_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del vit_attention_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating hyena-based ViT model...')\n",
    "vit_hyena_model = ViT(\n",
    "                            use_hyena=True,\n",
    "                            in_channels=in_ch,\n",
    "                            num_classes=out_ch,\n",
    "                            img_size=(t,h,w),\n",
    "                            spatial_dims=3,\n",
    "                            patch_size=vit_patch,\n",
    "                            classification=True\n",
    "                        ).to(device='cuda')\n",
    "hyena_num_params = count_parameters(vit_hyena_model)\n",
    "print(f\"\\tNumber of parameters with hyena: {hyena_num_params/1e6} million\")\n",
    "\n",
    "print('Running hyena-based ViT timing test...')\n",
    "hyena_time = time_run(input, vit_hyena_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "vit_hyena_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del vit_hyena_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print speedup\n",
    "speedup = [a/h for a, h in zip(attn_time, hyena_time)]\n",
    "print(f\"Average speedup: {np.mean(speedup)}x\")\n",
    "if np.abs(np.mean(speedup)-np.median(speedup)>0.1):\n",
    "    print(\"\\tWARNING: Mean and median are very different\")\n",
    "    print(f\"\\tMedian speedup: {np.median(speedup)}x\")\n",
    "\n",
    "# Plot speedup\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(speedup)\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Speedup (attention/hyena)\")  \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot raw timing data\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(attn_time,'r',label='Attention')\n",
    "plt.plot(hyena_time,'b',label='Hyena')\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Time (s)\")  \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_dict[key_count] = {'image_size': (batch,in_ch,h,w,t), \n",
    "                            'context_length':context_length, \n",
    "                            'speedup':np.mean(speedup),\n",
    "                            'attn_time':np.mean(attn_time),\n",
    "                            'hyena_time':np.mean(hyena_time), \n",
    "                            'attn_num_param':attn_num_params,\n",
    "                            'hyena_num_param':hyena_num_params}\n",
    "key_count+=1\n",
    "with open('/home/hoopersm/hyena/vit_speedup_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(speedup_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results from all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/hoopersm/hyena/vit_speedup_dict.pkl', 'rb') as f:\n",
    "    speedup_dict = pickle.load(f)\n",
    "key_count = len(speedup_dict)\n",
    "\n",
    "all_speedup = [speedup_dict[key]['speedup'] for key in speedup_dict.keys()]\n",
    "all_context_length = [speedup_dict[key]['context_length'] for key in speedup_dict.keys()]\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(all_context_length,all_speedup,'rx')\n",
    "plt.title(\"ViT speedup vs. context length\")\n",
    "plt.xlabel(\"Context length\")\n",
    "plt.ylabel(\"Speedup\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load timing dict to track results over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists('/home/hoopersm/hyena/swin_speedup_dict.pkl'):\n",
    "    with open('/home/hoopersm/hyena/swin_speedup_dict.pkl', 'rb') as f:\n",
    "        speedup_dict = pickle.load(f)\n",
    "    key_count = len(speedup_dict)\n",
    "    print('Loaded speedup_dict with {} entries'.format(key_count))\n",
    "else:\n",
    "    speedup_dict = {}\n",
    "    key_count = 0\n",
    "    print('Initialized speedup_dict, no entries yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "in_ch = 3\n",
    "out_ch = 1\n",
    "h = 224\n",
    "w = 224\n",
    "t = 32\n",
    "reps = 100\n",
    "\n",
    "swin_patch = (2,2,2) # (t,h,w)\n",
    "swin_window = (8,8,8) # (t,h,w)\n",
    "\n",
    "input = torch.zeros(((batch,in_ch,t,h,w))).to(device='cuda') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute context length for Swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max Swin context length\n",
    "context_length = swin_window[0] * swin_window[1] * swin_window[2]\n",
    "print('Max Swin context length: {}'.format(context_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating attention-based Swin model...')\n",
    "                    \n",
    "swin_attention_model = SwinTransformer(\n",
    "                            use_hyena=False,\n",
    "                            in_chans=in_ch,\n",
    "                            embed_dim=48,\n",
    "                            window_size=swin_window,\n",
    "                            patch_size=swin_patch,\n",
    "                            depths=[2,2,6,2],\n",
    "                            num_heads=[3,6,12,24],\n",
    "                            spatial_dims=3,\n",
    "                        ).to(device='cuda')\n",
    "attn_num_params = count_parameters(swin_attention_model)\n",
    "print(f\"\\tNumber of parameters with attention: {attn_num_params/1e6} million\")\n",
    "\n",
    "print('Running attention-based Swin timing test...')\n",
    "attn_time = time_run(input, swin_attention_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "swin_attention_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del swin_attention_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating hyena-based Swin model...')\n",
    "                    \n",
    "swin_hyena_model = SwinTransformer(\n",
    "                            use_hyena=True,\n",
    "                            in_chans=in_ch,\n",
    "                            embed_dim=48,\n",
    "                            window_size=swin_window,\n",
    "                            patch_size=swin_patch,\n",
    "                            depths=[2,2,6,2],\n",
    "                            num_heads=[3,6,12,24],\n",
    "                            spatial_dims=3,\n",
    "                        ).to(device='cuda')\n",
    "hyena_num_params = count_parameters(swin_hyena_model)\n",
    "print(f\"\\tNumber of parameters with hyena: {hyena_num_params/1e6} million\")\n",
    "\n",
    "print('Running hyena-based Swin timing test...')\n",
    "hyena_time = time_run(input, swin_hyena_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "swin_hyena_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del swin_hyena_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print speedup\n",
    "speedup = [a/h for a, h in zip(attn_time, hyena_time)]\n",
    "print(f\"Average speedup: {np.mean(speedup)}x\")\n",
    "if np.abs(np.mean(speedup)-np.median(speedup)>0.1):\n",
    "    print(\"\\tWARNING: Mean and median are very different\")\n",
    "    print(f\"\\tMedian speedup: {np.median(speedup)}x\")\n",
    "\n",
    "# Plot speedup\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(speedup)\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Speedup (attention/hyena)\")  \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot raw timing data\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(attn_time,'r',label='Attention')\n",
    "plt.plot(hyena_time,'b',label='Hyena')\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Time (s)\")  \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup_dict[key_count] = {'image_size': (batch,in_ch,h,w,t), \n",
    "                            'context_length':context_length, \n",
    "                            'speedup':np.mean(speedup),\n",
    "                            'attn_time':np.mean(attn_time),\n",
    "                            'hyena_time':np.mean(hyena_time), \n",
    "                            'attn_num_param':attn_num_params,\n",
    "                            'hyena_num_param':hyena_num_params}\n",
    "key_count+=1\n",
    "with open('/home/hoopersm/hyena/swin_speedup_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(speedup_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results from all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/hoopersm/hyena/swin_speedup_dict.pkl', 'rb') as f:\n",
    "    speedup_dict = pickle.load(f)\n",
    "key_count = len(speedup_dict)\n",
    "\n",
    "all_speedup = [speedup_dict[key]['speedup'] for key in speedup_dict.keys()]\n",
    "all_context_length = [speedup_dict[key]['context_length'] for key in speedup_dict.keys()]\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(all_context_length,all_speedup,'rx')\n",
    "plt.title(\"Swin speedup vs. context length\")\n",
    "plt.xlabel(\"Context length\")\n",
    "plt.ylabel(\"Speedup\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STCNNT Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load timing dict to track results over multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('/home/hoopersm/hyena/stcnnt_speedup_dict.pkl'):\n",
    "    with open('/home/hoopersm/hyena/stcnnt_speedup_dict.pkl', 'rb') as f:\n",
    "        speedup_dict = pickle.load(f)\n",
    "    key_count = len(speedup_dict)\n",
    "    print('Loaded speedup_dict with {} entries'.format(key_count))\n",
    "else:\n",
    "    speedup_dict = {}\n",
    "    key_count = 0\n",
    "    print('Initialized speedup_dict, no entries yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "in_ch = 3\n",
    "out_ch = 1\n",
    "h = 64\n",
    "w = 64\n",
    "t = 20\n",
    "reps = 100\n",
    "\n",
    "input = torch.zeros(((batch,in_ch,t,h,w))).to(device='cuda') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create config for STCNNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = parse_config()\n",
    "\n",
    "# attention modules\n",
    "config.kernel_size = 3\n",
    "config.stride = 1\n",
    "config.padding = 1\n",
    "config.stride_t = 2\n",
    "config.dropout_p = 0.1\n",
    "config.no_in_channel = in_ch\n",
    "config.C_out = out_ch\n",
    "config.height = h\n",
    "config.width = w\n",
    "config.batch_size = batch\n",
    "config.time = t\n",
    "config.norm_mode = \"instance2d\"\n",
    "config.a_type = \"conv\"\n",
    "config.is_causal = False\n",
    "config.n_head = 32\n",
    "config.interp_align_c = True\n",
    "\n",
    "config.window_size = [h//8, w//8]\n",
    "config.patch_size = [h//32, w//32]\n",
    "\n",
    "config.num_wind =[8, 8]\n",
    "config.num_patch =[2, 2]\n",
    "\n",
    "config.window_sizing_method = \"mixed\"\n",
    "\n",
    "# losses\n",
    "config.losses = [\"mse\"]\n",
    "config.loss_weights = [1.0]\n",
    "config.load_path = None\n",
    "\n",
    "# to be tested\n",
    "config.residual = True\n",
    "config.device = None\n",
    "config.channels = [16,32,64]\n",
    "config.all_w_decay = True\n",
    "config.optim = \"adamw\"\n",
    "config.scheduler = \"StepLR\"\n",
    "\n",
    "config.complex_i = False\n",
    "\n",
    "config.summary_depth = 4\n",
    "\n",
    "config.backbone_hrnet = Namespace()\n",
    "config.backbone_hrnet.C = 32\n",
    "config.backbone_hrnet.num_resolution_levels = 4\n",
    "\n",
    "config.backbone_hrnet.use_interpolation = True\n",
    "\n",
    "config.cell_type = \"sequential\"\n",
    "config.normalize_Q_K = True \n",
    "config.att_dropout_p = 0.0\n",
    "config.att_with_output_proj = True \n",
    "config.scale_ratio_in_mixer  = 1.0\n",
    "\n",
    "config.cosine_att = True\n",
    "config.att_with_relative_postion_bias = False\n",
    "\n",
    "config.block_dense_connection = True\n",
    "\n",
    "config.optim = \"adamw\"\n",
    "config.scheduler = \"ReduceLROnPlateau\"\n",
    "config.all_w_decay = True\n",
    "\n",
    "config.device = 'cuda'\n",
    "\n",
    "config.with_timer = True\n",
    "\n",
    "config.stride_s = 1\n",
    "config.separable_conv = True\n",
    "config.use_einsum = False\n",
    "\n",
    "config.mixer_kernel_size = 3\n",
    "config.mixer_stride = 1\n",
    "config.mixer_padding = 1\n",
    "\n",
    "config.mixer_type = 'conv'\n",
    "config.shuffle_in_window = False\n",
    "config.temporal_flash_attention = False \n",
    "config.activation_func = 'prelu'\n",
    "\n",
    "config.upsample_method = 'linear'\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "config.dropout_p = 0.1\n",
    "\n",
    "config.backbone_hrnet.block_str = [\"T1L1G1\",\n",
    "                \"T1L1G1\",\n",
    "                \"T1L1G1\",\n",
    "                \"T1L1G1\",\n",
    "                \"T1L1G1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute context length for STCNNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute max STCNNT context length\n",
    "# context_length = ???\n",
    "# print('Max STCNNT context length: {}'.format(context_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runing timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating attention-based STCNNT model...')\n",
    "                    \n",
    "hrnet_attention_model = STCNNT_HRnet(\n",
    "                            config\n",
    "                        ).to(device='cuda')\n",
    "attn_num_params = count_parameters(hrnet_attention_model)\n",
    "print(f\"\\tNumber of parameters with attention: {attn_num_params/1e6} million\")\n",
    "\n",
    "print('Running attention-based HRNET timing test...')\n",
    "attn_time = time_run(input, hrnet_attention_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "hrnet_attention_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del hrnet_attention_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO\n",
    "\n",
    "print('Creating hyena-based Swin model...')\n",
    "                    \n",
    "swin_hyena_model = SwinTransformer(\n",
    "                            use_hyena=True,\n",
    "                            in_chans=in_ch,\n",
    "                            embed_dim=48,\n",
    "                            window_size=swin_window,\n",
    "                            patch_size=swin_patch,\n",
    "                            depths=[2,2,6,2],\n",
    "                            num_heads=[3,6,12,24],\n",
    "                            spatial_dims=3,\n",
    "                        ).to(device='cuda')\n",
    "hyena_num_params = count_parameters(swin_hyena_model)\n",
    "print(f\"\\tNumber of parameters with hyena: {hyena_num_params/1e6} million\")\n",
    "\n",
    "print('Running hyena-based Swin timing test...')\n",
    "hyena_time = time_run(input, swin_hyena_model, reps)\n",
    "\n",
    "# Clean up model\n",
    "swin_hyena_model.to(device='cpu')\n",
    "torch.cuda.empty_cache()\n",
    "del swin_hyena_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO\n",
    "\n",
    "# Print speedup\n",
    "speedup = [a/h for a, h in zip(attn_time, hyena_time)]\n",
    "print(f\"Average speedup: {np.mean(speedup)}x\")\n",
    "if np.abs(np.mean(speedup)-np.median(speedup)>0.1):\n",
    "    print(\"\\tWARNING: Mean and median are very different\")\n",
    "    print(f\"\\tMedian speedup: {np.median(speedup)}x\")\n",
    "\n",
    "# Plot speedup\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(speedup)\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Speedup (attention/hyena)\")  \n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot raw timing data\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(attn_time,'r',label='Attention')\n",
    "plt.plot(hyena_time,'b',label='Hyena')\n",
    "plt.xlabel(\"Repetition\")\n",
    "plt.ylabel(\"Time (s)\")  \n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results into dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO\n",
    "\n",
    "speedup_dict[key_count] = {'image_size': (batch,in_ch,h,w,t), \n",
    "                            'context_length':context_length, \n",
    "                            'speedup':np.mean(speedup),\n",
    "                            'attn_time':np.mean(attn_time),\n",
    "                            'hyena_time':np.mean(hyena_time), \n",
    "                            'attn_num_param':attn_num_params,\n",
    "                            'hyena_num_param':hyena_num_params}\n",
    "key_count+=1\n",
    "with open('/home/hoopersm/hyena/swin_speedup_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(speedup_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results from all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO\n",
    "\n",
    "with open('/home/hoopersm/hyena/swin_speedup_dict.pkl', 'rb') as f:\n",
    "    speedup_dict = pickle.load(f)\n",
    "key_count = len(speedup_dict)\n",
    "\n",
    "all_speedup = [speedup_dict[key]['speedup'] for key in speedup_dict.keys()]\n",
    "all_context_length = [speedup_dict[key]['context_length'] for key in speedup_dict.keys()]\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(all_context_length,all_speedup,'rx')\n",
    "plt.title(\"ViT speedup vs. context length\")\n",
    "plt.xlabel(\"Context length\")\n",
    "plt.ylabel(\"Speedup\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4KaggleEnv",
   "language": "python",
   "name": "ai4kaggleenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
